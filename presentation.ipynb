{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58aa1968",
   "metadata": {},
   "source": [
    "## Presentation (Score-Ratio Metric and TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c0ddf3bc497ef93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:14.176205Z",
     "start_time": "2025-11-14T20:48:13.666146Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from scipy.sparse import load_npz\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9aa4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01a8fa0330779c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:14.188100Z",
     "start_time": "2025-11-14T20:48:14.184034Z"
    }
   },
   "outputs": [],
   "source": [
    "contraction_map = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"here's\": \"here is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"gotta\": \"got to\",\n",
    "    \"lemme\": \"let me\",\n",
    "    \"gimme\": \"give me\",\n",
    "    \"kinda\": \"kind of\",\n",
    "    \"ain’t\": \"am not\",\n",
    "    \"y’all\": \"you all\",\n",
    "    \"could’ve\": \"could have\",\n",
    "    \"should’ve\": \"should have\",\n",
    "    \"would’ve\": \"would have\",\n",
    "    \"might’ve\": \"might have\",\n",
    "    \"must’ve\": \"must have\",\n",
    "    \"shan’t\": \"shall not\",\n",
    "    \"let’s\": \"let us\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e2b5be9908030e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:14.195022Z",
     "start_time": "2025-11-14T20:48:14.193058Z"
    }
   },
   "outputs": [],
   "source": [
    "def expand_contractions(text):\n",
    "    for contraction, expanded in contraction_map.items():\n",
    "        text = text.replace(contraction, expanded)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e944c9863fd9fde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:26.193423Z",
     "start_time": "2025-11-14T20:48:26.189231Z"
    }
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "import certifi\n",
    "ssl._create_default_https_context = lambda: ssl.create_default_context(cafile=certifi.where())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a73df4e61ebe2952",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:26.341514Z",
     "start_time": "2025-11-14T20:48:26.335926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 221.31 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "def expand_contractions(text):\n",
    "    for contraction, expanded in contraction_map.items():\n",
    "        text = text.replace(contraction, expanded)\n",
    "    return text\n",
    "stop_words = set(stopwords.words('english')) - {\"not\", \"no\", \"never\"}\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_text(text):\n",
    "    text = expand_contractions(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "178ce3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8d0e6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 602.66 MiB, increment: 381.50 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit tf_idf_matrix = load_npz(\"Dataset/sparse_matrix.npz\").astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e03d218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 529.17 MiB, increment: 30.77 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "word_index_df = pd.read_csv('Dataset/word_to_index.csv', keep_default_na=False)\n",
    "word_index_df['index'] = word_index_df['index'].astype(np.int32)\n",
    "unique_words = dict(zip(word_index_df['word'], word_index_df['index']))\n",
    "del word_index_df\n",
    "temp_idf = pd.read_csv('Dataset/idf.csv', keep_default_na=False)\n",
    "idf = dict(zip(temp_idf['word'], temp_idf['idf_score']))\n",
    "del temp_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72ea7cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 750.86 MiB, increment: 218.98 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "df = pd.read_csv(\"Dataset/400k.csv\",usecols=['Id','Score_question','question','Score_answer','Body_answer'])#pd.read_csv(\"Dataset/cleaned.csv\",usecols=['Id','Score_question','question','Score_answer','Body_answer'])\n",
    "df['Score_question'] = df['Score_question'].astype(np.int16)\n",
    "df['Score_answer'] = df['Score_answer'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63472373ab1661e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:37.326051Z",
     "start_time": "2025-11-14T20:48:27.051782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%%memit\\nword_index_df = pd.read_csv(\\'Dataset/word_to_index.csv\\', keep_default_na=False)\\nword_index_df[\\'index\\'] = word_index_df[\\'index\\'].astype(np.int32)\\nunique_words = dict(zip(word_index_df[\\'word\\'], word_index_df[\\'index\\']))\\ndel word_index_df\\ntemp_idf = pd.read_csv(\\'Dataset/idf.csv\\', keep_default_na=False)\\nidf = dict(zip(temp_idf[\\'word\\'], temp_idf[\\'idf_score\\']))\\ndel temp_idf\\ntf_idf_matrix = load_npz(\"Dataset/sparse_matrix.npz\")\\ndf = pd.read_csv(\"Dataset/cleaned.csv\",usecols=[\\'Id\\',\\'Score_question\\',\\'question\\',\\'Score_answer\\',\\'Body_answer\\'])\\ndf[\\'Score_question\\'] = df[\\'Score_question\\'].astype(np.int16)\\ndf[\\'Score_answer\\'] = df[\\'Score_answer\\'].astype(np.int16)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"%%memit\n",
    "word_index_df = pd.read_csv('Dataset/word_to_index.csv', keep_default_na=False)\n",
    "word_index_df['index'] = word_index_df['index'].astype(np.int32)\n",
    "unique_words = dict(zip(word_index_df['word'], word_index_df['index']))\n",
    "del word_index_df\n",
    "temp_idf = pd.read_csv('Dataset/idf.csv', keep_default_na=False)\n",
    "idf = dict(zip(temp_idf['word'], temp_idf['idf_score']))\n",
    "del temp_idf\n",
    "tf_idf_matrix = load_npz(\"Dataset/sparse_matrix.npz\")\n",
    "df = pd.read_csv(\"Dataset/cleaned.csv\",usecols=['Id','Score_question','question','Score_answer','Body_answer'])\n",
    "df['Score_question'] = df['Score_question'].astype(np.int16)\n",
    "df['Score_answer'] = df['Score_answer'].astype(np.int16)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ddb0f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could go only best answers if needed (would cut down a lot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f79cb870c41456cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:37.344575Z",
     "start_time": "2025-11-14T20:48:37.338253Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def chatbot_reply(user_query):\n",
    "    user_query = preprocess_text(user_query).split()\n",
    "    tf = Counter(user_query)\n",
    "    length = len(user_query)\n",
    "    data,cols = [],[]\n",
    "    for word,count in tf.items():\n",
    "        if word in unique_words:\n",
    "            data.append((count/length)*idf[word])\n",
    "            cols.append(unique_words[word])\n",
    "    query_vec = csr_matrix((data, ([0]*len(cols), cols)), shape=(1, len(unique_words)))\n",
    "    similarity = cosine_similarity(query_vec, tf_idf_matrix).flatten()\n",
    "    idx = similarity.argmax()\n",
    "    print(idx)\n",
    "    unique_df = df[['Score_question',\"Id\"]].drop_duplicates()\n",
    "    Id = unique_df.iloc[idx]['Id']\n",
    "    best_ans = df[df['Id'] == Id].sort_values('Score_answer',ascending=False).iloc[0]\n",
    "    return best_ans[\"Body_answer\"], best_ans[\"question\"], similarity[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccc3b83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(31340)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[469]['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40be911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('alright, i\\'ll give it a try. \"broken pipe\" on the server side usually means that the client closes the connection while the server is still sending data. from your previous question, i assume your client is a browser (using the tag). that most probably means that the browser does not support playback of mpeg transport streams. actually i haven\\'t heard of any browser that supports it. maybe you should try to stream an ogg theora video (mime type \"video/theora\") for testing - firefox 3.1+ supports this out of the box. if that works, your server implementation is correct.',\n",
       " 'use http response preparing response http request send video receiving error broken pipe f open r return response work fine f open r return suspect related mimetype issue one suggest use basehttpserver',\n",
       " np.float64(0.7529698796132007))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_reply(\"how to reverse a list in Python?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b971d1c36baa46f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:37.358381Z",
     "start_time": "2025-11-14T20:48:37.354322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 920.16 MiB, increment: 1.30 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "def top_n_results(user_query,n=1,score_req = 10):\n",
    "    user_query = preprocess_text(user_query).split()\n",
    "    tf = Counter(user_query)\n",
    "    length = len(user_query)\n",
    "    data,cols = [],[]\n",
    "    for word,count in tf.items():\n",
    "        if word in unique_words:\n",
    "            data.append((count/length)*idf[word])\n",
    "            cols.append(unique_words[word])\n",
    "    query_vec = csr_matrix((data, ([0]*len(cols), cols)), shape=(1, len(unique_words)))\n",
    "    similarity = cosine_similarity(query_vec, tf_idf_matrix).flatten()\n",
    "    idx = np.argsort(-similarity)[:n]\n",
    "    values = -np.sort(-similarity)[:n]\n",
    "    idx_values = pd.DataFrame({'Id':unique_df.iloc[idx]['Id'], 'Similarity':values})\n",
    "    Id = unique_df.iloc[idx]['Id']\n",
    "    best_ans = df[df['Id'].isin(Id)]\n",
    "    best_ans = best_ans[best_ans['Score_answer']>=score_req]\n",
    "    return best_ans.merge(idx_values, on='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "260e27e91b5523b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:37.507639Z",
     "start_time": "2025-11-14T20:48:37.501717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 920.67 MiB, increment: 0.36 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "def top_n_interval_filtered(user_query,n=1,score_req=10,lower_bound=0,upper_bound=1,lowest_question_score=0):\n",
    "    unique_df = df[['Score_question',\"Id\"]].drop_duplicates()\n",
    "    user_query = preprocess_text(user_query).split()\n",
    "    tf = Counter(user_query)\n",
    "    length = len(user_query)\n",
    "    data, cols = [], []\n",
    "    for word, count in tf.items():\n",
    "        if word in unique_words:\n",
    "            data.append((count / length) * idf[word])\n",
    "            cols.append(unique_words[word])\n",
    "    query_vec = csr_matrix(\n",
    "        (data, ([0] * len(cols), cols)),\n",
    "        shape=(1, len(unique_words))\n",
    "    )\n",
    "    similarity = cosine_similarity(query_vec, tf_idf_matrix).flatten()\n",
    "    idx = np.argsort(-similarity)[:n]\n",
    "    values = -np.sort(-similarity)[:n]\n",
    "    idx_values = pd.DataFrame({\n",
    "        'Id': unique_df.iloc[idx]['Id'],\n",
    "        'Similarity': values\n",
    "    })\n",
    "    top_answers = df[df['Id'].isin(idx_values['Id'])]\n",
    "    top_answers = top_answers[top_answers['Score_answer'] >= score_req]\n",
    "    merged = top_answers.merge(idx_values, on='Id')\n",
    "    merged['Score_ratio'] = abs(merged[\"Score_question\"]).div(merged[\"Score_answer\"].dropna())\n",
    "    filtered = merged[\n",
    "        (merged[\"Score_ratio\"] >= lower_bound) &\n",
    "        (merged[\"Score_ratio\"] <= upper_bound) &\n",
    "        (merged[\"Score_question\"] > lowest_question_score)\n",
    "    ]\n",
    "    return filtered.sort_values(by=\"Similarity\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc204b939737f15c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:39.853041Z",
     "start_time": "2025-11-14T20:48:37.515865Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/pandas/core/indexing.py:1714\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1716\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/pandas/core/generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4145\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4146\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4154\u001b[0m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/pandas/core/generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4131\u001b[0m     )\n\u001b[0;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4140\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/pandas/core/internals/managers.py:891\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    890\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m--> 891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/pandas/core/indexers/utils.py:282\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmemit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop_n_interval_filtered(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow can I use newline characters in python?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,10,0,0,3,0)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2482\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2480\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2482\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2486\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/memory_profiler.py:1113\u001b[0m, in \u001b[0;36mMemoryProfilerMagics.memit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m counter \u001b[38;5;241m<\u001b[39m repeat:\n\u001b[1;32m   1112\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1113\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m \u001b[43mmemory_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_func_exec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_ns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mmax_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m                       \u001b[49m\u001b[43minclude_children\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_children\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1117\u001b[0m     mem_usage\u001b[38;5;241m.\u001b[39mappend(tmp)\n\u001b[1;32m   1119\u001b[0m result \u001b[38;5;241m=\u001b[39m MemitResult(mem_usage, baseline, repeat, timeout, interval,\n\u001b[1;32m   1120\u001b[0m                      include_children)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/memory_profiler.py:379\u001b[0m, in \u001b[0;36mmemory_usage\u001b[0;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend, max_iterations)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# When there is an exception in the \"proc\" - the (spawned) monitoring processes don't get killed.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     returned \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     parent_conn\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# finish timing\u001b[39;00m\n\u001b[1;32m    381\u001b[0m     ret \u001b[38;5;241m=\u001b[39m parent_conn\u001b[38;5;241m.\u001b[39mrecv()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/memory_profiler.py:889\u001b[0m, in \u001b[0;36m_func_exec\u001b[0;34m(stmt, ns)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_func_exec\u001b[39m(stmt, ns):\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;66;03m# helper for magic_memit, just a function proxy for the exec\u001b[39;00m\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;66;03m# statement\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mns\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "File \u001b[0;32m<string>:19\u001b[0m, in \u001b[0;36mtop_n_interval_filtered\u001b[0;34m(user_query, n, score_req, lower_bound, upper_bound, lowest_question_score)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/pandas/core/indexing.py:1743\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1747\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/pandas/core/indexing.py:1717\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1716\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[0;32m-> 1717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "%memit top_n_interval_filtered(\"How can I use newline characters in python?\",10,0,0,3,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57cab226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsc80/lib/python3.12/multiprocessing/resource_tracker.py:147: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "peak memory: 1127.73 MiB, increment: 846.62 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "user_query = input(\"Enter query: \")\n",
    "chatbot_reply(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49da8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
