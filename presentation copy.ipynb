{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58aa1968",
   "metadata": {},
   "source": [
    "## Presentation (Score-Ratio Metric and TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c0ddf3bc497ef93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:14.176205Z",
     "start_time": "2025-11-14T20:48:13.666146Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from scipy.sparse import load_npz\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9aa4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01a8fa0330779c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:14.188100Z",
     "start_time": "2025-11-14T20:48:14.184034Z"
    }
   },
   "outputs": [],
   "source": [
    "contraction_map = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"here's\": \"here is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"gotta\": \"got to\",\n",
    "    \"lemme\": \"let me\",\n",
    "    \"gimme\": \"give me\",\n",
    "    \"kinda\": \"kind of\",\n",
    "    \"ain’t\": \"am not\",\n",
    "    \"y’all\": \"you all\",\n",
    "    \"could’ve\": \"could have\",\n",
    "    \"should’ve\": \"should have\",\n",
    "    \"would’ve\": \"would have\",\n",
    "    \"might’ve\": \"might have\",\n",
    "    \"must’ve\": \"must have\",\n",
    "    \"shan’t\": \"shall not\",\n",
    "    \"let’s\": \"let us\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e2b5be9908030e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:14.195022Z",
     "start_time": "2025-11-14T20:48:14.193058Z"
    }
   },
   "outputs": [],
   "source": [
    "def expand_contractions(text):\n",
    "    for contraction, expanded in contraction_map.items():\n",
    "        text = text.replace(contraction, expanded)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e944c9863fd9fde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:26.193423Z",
     "start_time": "2025-11-14T20:48:26.189231Z"
    }
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "import certifi\n",
    "ssl._create_default_https_context = lambda: ssl.create_default_context(cafile=certifi.where())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a73df4e61ebe2952",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:26.341514Z",
     "start_time": "2025-11-14T20:48:26.335926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 159.91 MiB, increment: 0.19 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "def expand_contractions(text):\n",
    "    for contraction, expanded in contraction_map.items():\n",
    "        text = text.replace(contraction, expanded)\n",
    "    return text\n",
    "stop_words = set(stopwords.words('english')) - {\"not\", \"no\", \"never\"}\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_text(text):\n",
    "    text = expand_contractions(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "178ce3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8d0e6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 415.45 MiB, increment: 254.33 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit tf_idf_matrix = load_npz(\"Dataset/sparse_matrix.npz\").astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e03d218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 157.95 MiB, increment: 0.56 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "word_index_df = pd.read_csv('Dataset/word_to_index.csv', keep_default_na=False)\n",
    "word_index_df['index'] = word_index_df['index'].astype(np.int32)\n",
    "unique_words = dict(zip(word_index_df['word'], word_index_df['index']))\n",
    "del word_index_df\n",
    "temp_idf = pd.read_csv('Dataset/idf.csv', keep_default_na=False)\n",
    "idf = dict(zip(temp_idf['word'], temp_idf['idf_score']))\n",
    "del temp_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72ea7cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 762.72 MiB, increment: 600.44 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "df = pd.read_csv(\"Dataset/best_ans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ddb0f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could go only best answers if needed (would cut down a lot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f79cb870c41456cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T20:48:37.344575Z",
     "start_time": "2025-11-14T20:48:37.338253Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def chatbot_reply(user_query):\n",
    "    user_query = preprocess_text(user_query).split()\n",
    "    tf = Counter(user_query)\n",
    "    length = len(user_query)\n",
    "    data,cols = [],[]\n",
    "    for word,count in tf.items():\n",
    "        if word in unique_words:\n",
    "            data.append((count/length)*idf[word])\n",
    "            cols.append(unique_words[word])\n",
    "    query_vec = csr_matrix((data, ([0]*len(cols), cols)), shape=(1, len(unique_words)))\n",
    "    similarity = cosine_similarity(query_vec, tf_idf_matrix).flatten()\n",
    "    idx = similarity.argmax()\n",
    "    print(idx)\n",
    "    Id = df.iloc[idx]['Id']\n",
    "    return df.iloc[idx]['Body_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccc3b83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(126524)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[469]['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40be911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'alright, i\\'ll give it a try. \"broken pipe\" on the server side usually means that the client closes the connection while the server is still sending data. from your previous question, i assume your client is a browser (using the tag). that most probably means that the browser does not support playback of mpeg transport streams. actually i haven\\'t heard of any browser that supports it. maybe you should try to stream an ogg theora video (mime type \"video/theora\") for testing - firefox 3.1+ supports this out of the box. if that works, your server implementation is correct.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_reply(\"how to reverse a list in Python?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57cab226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199621\n",
      "peak memory: 829.38 MiB, increment: 557.28 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "user_query = input(\"Enter query: \")\n",
    "chatbot_reply(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49da8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
