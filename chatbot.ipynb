{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "import re\n",
    "import tqdm\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.sparse import save_npz, load_npz\n",
    "import functions\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in data\n",
    "tf_idf_matrix = load_npz(\"Dataset/sparse_matrix.npz\")\n",
    "df = pd.read_csv(\"Dataset/cleaned.csv\",usecols = ['Id','Score_question','question','Score_answer','Body_answer'])\n",
    "word_index_df = pd.read_csv('Dataset/word_to_index.csv', keep_default_na=False)\n",
    "unique_words = dict(zip(word_index_df['word'], word_index_df['index']))\n",
    "idf = pd.read_csv('Dataset/idf.csv', keep_default_na=False)\n",
    "idf = dict(zip(idf['word'], idf['idf_score']))\n",
    "df = df.dropna()\n",
    "unique_df = df[['question',\"Id\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) - {\"not\", \"no\", \"never\"}\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_text(text):\n",
    "    # Expand contractions\n",
    "    text = functions.expand_contractions(text)\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Lowercase and keep only alphabetic words\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "\n",
    "    # Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the most similar question, and the highest rated answer for that question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_reply(user_query):\n",
    "    # Transform user query into TF-IDF vector using the same steps we did on the dataframe\n",
    "    user_query = preprocess_text(user_query).split()\n",
    "    tf = Counter(user_query)\n",
    "    length = len(user_query)\n",
    "    data,cols = [],[]\n",
    "    for word,count in tf.items():\n",
    "        if word in unique_words:\n",
    "            data.append((count/length)*idf[word])\n",
    "            cols.append(unique_words[word])\n",
    "    query_vec = csr_matrix((data, ([0]*len(cols), cols)), shape=(1, len(unique_words)))\n",
    "\n",
    "    # Compute cosine similarity across whole df\n",
    "    similarity = cosine_similarity(query_vec, tf_idf_matrix).flatten()\n",
    "    \n",
    "    # Find the most similar question\n",
    "    idx = similarity.argmax()\n",
    "    Id = unique_df.iloc[idx]['Id']\n",
    "    best_ans = df[df['Id'] == Id].sort_values('Score_answer',ascending=False).iloc[0]\n",
    "    # Retrieve the best matching Q&A\n",
    "    return best_ans[\"Body_answer\"], best_ans[\"question\"], similarity[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the n most similar questions, and their corresponding answers with a score>=score_req. Returns a dataframe, with all the original columns and similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_results(user_query,n=1,score_req = 10):\n",
    "    # Transform user query into TF-IDF vector\n",
    "    user_query = preprocess_text(user_query).split()\n",
    "    tf = Counter(user_query)\n",
    "    length = len(user_query)\n",
    "    data,cols = [],[]\n",
    "    for word,count in tf.items():\n",
    "        if word in unique_words:\n",
    "            data.append((count/length)*idf[word])\n",
    "            cols.append(unique_words[word])\n",
    "    query_vec = csr_matrix((data, ([0]*len(cols), cols)), shape=(1, len(unique_words)))\n",
    "\n",
    "    # Compute cosine similarity across whole df\n",
    "    similarity = cosine_similarity(query_vec, tf_idf_matrix).flatten()\n",
    "    # Find the most similar question(s)\n",
    "    idx = np.argsort(-similarity)[:n]\n",
    "    values = -np.sort(-similarity)[:n]\n",
    "    idx_values = pd.DataFrame({'Id':unique_df.iloc[idx]['Id'], 'Similarity':values})\n",
    "    Id = unique_df.iloc[idx]['Id']\n",
    "    best_ans = df[df['Id'].isin(Id)]\n",
    "    best_ans = best_ans[best_ans['Score_answer']>=score_req]\n",
    "    return best_ans.merge(idx_values, on='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = top_n_results(\"How to print a backslash in Python?\",n=5,score_req=10)['Body_answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the n most similar questions with a score>=lowest_question_score, and their corresponding answers with a score>=score_req, an upper_bound>=score_ratio>=lower_bound. Returns a dataframe, with all the original columns, as well as similarity and Score_ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_interval_filtered(user_query,n=1,score_req=10,lower_bound=0,upper_bound=1,lowest_question_score=0):\n",
    "    # Transform user query into TF-IDF vector\n",
    "    user_query = preprocess_text(user_query).split()\n",
    "    tf = Counter(user_query)\n",
    "    length = len(user_query)\n",
    "    data, cols = [], []\n",
    "    for word, count in tf.items():\n",
    "        if word in unique_words:\n",
    "            data.append((count / length) * idf[word])\n",
    "            cols.append(unique_words[word])\n",
    "    query_vec = csr_matrix(\n",
    "        (data, ([0] * len(cols), cols)),\n",
    "        shape=(1, len(unique_words))\n",
    "    )\n",
    "     # Compute cosine similarity across whole df\n",
    "    similarity = cosine_similarity(query_vec, tf_idf_matrix).flatten()\n",
    "    # Find the most similar question(s)\n",
    "    idx = np.argsort(-similarity)[:n]\n",
    "    values = -np.sort(-similarity)[:n]\n",
    "    idx_values = pd.DataFrame({\n",
    "        'Id': unique_df.iloc[idx]['Id'],\n",
    "        'Similarity': values\n",
    "    })\n",
    "    top_answers = df[df['Id'].isin(idx_values['Id'])]\n",
    "    top_answers = top_answers[top_answers['Score_answer'] >= score_req] #Filter on score_req for answer\n",
    "    merged = top_answers.merge(idx_values, on='Id')\n",
    "    merged['Score_ratio'] = abs(merged[\"Score_question\"]).div(merged[\"Score_answer\"].dropna())\n",
    "    # Filter on score ratio and question score\n",
    "    filtered = merged[\n",
    "        (merged[\"Score_ratio\"] >= lower_bound) &\n",
    "        (merged[\"Score_ratio\"] <= upper_bound) &\n",
    "        (merged[\"Score_question\"] > lowest_question_score)\n",
    "    ]\n",
    "    return filtered.sort_values(by=\"Similarity\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a prompt for an LLM to answer user question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_string(user_query):\n",
    "    results = top_n_interval_filtered(user_query,n=5,score_req=10,lower_bound=0,upper_bound=1.5,lowest_question_score=0)\n",
    "    str = ''\n",
    "    count = 0\n",
    "    for ans in temp:\n",
    "        count+=1\n",
    "        str += f'Answer {count}:\\n{ans}\\n\\n'\n",
    "    #work on prompt\n",
    "    instructions = 'Answer this question based on the following answers from Stack Overflow. If none of the answers are relevant, or there are no answers respond with \"I do not know\".\\n\\n'\n",
    "    str = instructions + f'Question:\\n{user_query}\\n\\n' + str\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer this question based on the following answers from Stack Overflow. If none of the answers are relevant, or there are no answers respond with \"I do not know\".\\n\\nQuestion:\\nhow to print escape character\\n\\nAnswer 1:\\nNo need to use str.replace or string.replace here, just convert that string to a raw string:\\n\\n>>> strs = r\"C:\\\\Users\\\\Josh\\\\Desktop\\\\20130216\"\\n           ^\\n           |\\n       notice the \\'r\\'\\n\\n\\nBelow is the repr version of the above string, that\\'s why you\\'re seeing \\\\\\\\ here.\\nBut, in fact the actual string contains just \\'\\\\\\' not \\\\\\\\.\\n\\n>>> strs\\n\\'C:\\\\\\\\Users\\\\\\\\Josh\\\\\\\\Desktop\\\\\\\\20130216\\'\\n\\n>>> s = r\"f\\\\o\"\\n>>> s            #repr representation\\n\\'f\\\\\\\\o\\'\\n>>> len(s)   #length is 3, as there\\'s only one `\\'\\\\\\'`\\n3\\n\\n\\nBut when you\\'re going to print this string you\\'ll not get \\'\\\\\\\\\\' in the output.\\n\\n>>> print strs\\nC:\\\\Users\\\\Josh\\\\Desktop\\\\20130216\\n\\n\\nIf you want the string to show \\'\\\\\\\\\\' during print then use str.replace:\\n\\n>>> new_strs = strs.replace(\\'\\\\\\\\\\',\\'\\\\\\\\\\\\\\\\\\')\\n>>> print new_strs\\nC:\\\\\\\\Users\\\\\\\\Josh\\\\\\\\Desktop\\\\\\\\20130216\\n\\n\\nrepr version will now show \\\\\\\\\\\\\\\\:\\n\\n>>> new_strs\\n\\'C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\Josh\\\\\\\\\\\\\\\\Desktop\\\\\\\\\\\\\\\\20130216\\'\\n\\n\\n\\nAnswer 2:\\nYou need to escape your backslash by preceding it with, yes, another backslash:\\n\\nprint \"\\\\\\\\\"\\n\\n\\nThe \\\\ character is called an escape character, which interprets the character following it differently. For example, n by itself is simply a letter, but when you precede it with a backslash, it becomes \\\\n, which is the newline character.\\n\\nAs you can probably guess, \\\\ also needs to be escaped so it doesn\\'t function like an escape character. You have to... escape the escape, essentially.\\n\\n\\nAnswer 3:\\nAnother clue, if you\\'re trying to accomplish something more complicated than just printing a backlash, you can declare a string as raw (with and r in front of it) and it will print all its characters as is:\\n\\n>>> s = r\\'\\\\abc\\\\def\\'\\n>>> print s\\n\\'\\\\abc\\\\def\\'\\n\\n\\nThis is useful for regular expressions. You can find more information in the docs.\\n\\n\\nAnswer 4:\\nYou have the right idea with escaping the backslashes, but despite how it looks, your input string doesn\\'t actually have any backslashes in it. You need to escape them in the input, too!\\n\\n>>> a = \"1\\\\\\\\2\\\\\\\\3\\\\\\\\4\"  # Note the doubled backslashes here!\\n>>> print(a.split(\\'\\\\\\\\\\'))  # Split on \\'\\\\\\\\\\'\\n[\\'1\\', \\'2\\', \\'3\\', \\'4\\']\\n\\n\\nYou could also use a raw string literal for the input, if it\\'s likely to have many backslashes. This notation is much cleaner to look at (IMO), but it does have some limitations: read the docs!\\n\\n>>> a = r\"1\\\\2\\\\3\\\\4\"\\n>>> print(a.split(\\'\\\\\\\\\\'))\\n[\\'1\\', \\'2\\', \\'3\\', \\'4\\']\\n\\n\\n\\n\\nIf you\\'re getting a elsewhere, and a.split(\\'\\\\\\\\\\') doesn\\'t appropriately split on the visible backslashes, that means you\\'ve got something else in there instead of real backslashes. Try print(repr(a)) to see what the \"literal\" string actually looks like.\\n\\n>>> a = \\'1\\\\2\\\\3\\\\4\\'\\n>>> print(a)\\n1â\\x98»â\\x99¥â\\x99¦\\n>>> print(repr(a))\\n\\'1\\\\x02\\\\x03\\\\x04\\'\\n\\n>>> b = \\'1\\\\\\\\2\\\\\\\\3\\\\\\\\4\\'\\n>>> print(b)\\n1\\\\2\\\\3\\\\4\\n>>> print(repr(b))\\n\\'1\\\\\\\\2\\\\\\\\3\\\\\\\\4\\'\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_summary_string(\"how to print escape character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make decisions or predictions.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "gemini_api_key = os.getenv(\"api_key\")\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers user question based on retrived answers through gemeni 2.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_response(user_query):\n",
    "    prompt = create_summary_string(user_query)\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=prompt,\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To print an escape character, specifically a backslash (`\\\\`), you need to escape it by preceding it with another backslash.\\n\\n*   **To print a single backslash:**\\n    ```python\\n    print \"\\\\\\\\\"\\n    ```\\n    The `\\\\` character is an escape character itself, so `\\\\\\\\` tells the interpreter to treat the second `\\\\` as a literal backslash rather than the start of an escape sequence.\\n\\n*   **To print a string containing multiple backslashes (e.g., file paths):**\\n    You have a couple of options:\\n    1.  **Escape each backslash:** Use `\\\\\\\\` for every literal backslash you want in the string.\\n        ```python\\n        path = \"C:\\\\\\\\Users\\\\\\\\Josh\\\\\\\\Desktop\"\\n        print path\\n        # Output: C:\\\\Users\\\\Josh\\\\Desktop\\n        ```\\n    2.  **Use a raw string:** Declare the string as raw by placing an `r` before the opening quote. In a raw string, backslashes are treated literally and are not interpreted as escape characters. This is often cleaner for paths or regular expressions.\\n        ```python\\n        path = r\"C:\\\\Users\\\\Josh\\\\Desktop\\\\20130216\"\\n        print path\\n        # Output: C:\\\\Users\\\\Josh\\\\Desktop\\\\20130216\\n        \\n        s = r\\'\\\\abc\\\\def\\'\\n        print s\\n        # Output: \\\\abc\\\\def\\n        ```\\n\\n*   **If you specifically want the output to show double backslashes (`\\\\\\\\`)** (e.g., for `repr` like representation):\\n    You would need to ensure the string itself contains double backslashes for each single backslash you want to appear in the output. This can be done by replacing single backslashes with double ones:\\n    ```python\\n    strs = r\"C:\\\\Users\\\\Josh\\\\Desktop\\\\20130216\"\\n    new_strs = strs.replace(\\'\\\\\\\\\\',\\'\\\\\\\\\\\\\\\\\\')\\n    print new_strs\\n    # Output: C:\\\\\\\\Users\\\\\\\\Josh\\\\\\\\Desktop\\\\\\\\20130216\\n    ```'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gemini_response(\"how to print escape character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
