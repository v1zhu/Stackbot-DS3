{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58aa1968",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "This notebook will allow us to explore the data found in the Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4177c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import html\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4adf48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'questions = pd.read_csv(\"Dataset/Questions.csv\",encoding=\\'latin-1\\')\\nanswers = pd.read_csv(\"Dataset/Answers.csv\",encoding=\\'latin-1\\')\\ntags = pd.read_csv(\"Dataset/Tags.csv\",encoding=\\'latin-1\\')\\ntag_question = tags.groupby(\\'Id\\').agg(list).merge(questions,how=\\'inner\\',on = \"Id\")\\ndf = tag_question.merge(answers,how = \"inner\",left_on = \"Id\", right_on = \"ParentId\")\\ndf.columns = df.columns.str.replace(\"_x\",\"_question\").str.replace(\"_y\",\"_answer\")\\ndf = df[[\\'Id\\',\\'Tag\\',\\'Score_question\\',\\'Title\\',\\'Body_question\\',\"Score_answer\",\"Body_answer\"]]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"questions = pd.read_csv(\"Dataset/Questions.csv\",encoding='latin-1')\n",
    "answers = pd.read_csv(\"Dataset/Answers.csv\",encoding='latin-1')\n",
    "tags = pd.read_csv(\"Dataset/Tags.csv\",encoding='latin-1')\n",
    "tag_question = tags.groupby('Id').agg(list).merge(questions,how='inner',on = \"Id\")\n",
    "df = tag_question.merge(answers,how = \"inner\",left_on = \"Id\", right_on = \"ParentId\")\n",
    "df.columns = df.columns.str.replace(\"_x\",\"_question\").str.replace(\"_y\",\"_answer\")\n",
    "df = df[['Id','Tag','Score_question','Title','Body_question',\"Score_answer\",\"Body_answer\"]]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad436898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample_df = df.head(10000)\\nsample_df.to_csv(\"Dataset/sample\")'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"sample_df = df.head(10000)\n",
    "sample_df.to_csv(\"Dataset/sample\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254cc6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_map = {\n",
    "    # Negative contractions\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \n",
    "    # Pronoun contractions\n",
    "    \"i'm\": \"i am\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \n",
    "    # Misc contractions\n",
    "    \"let's\": \"let us\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"here's\": \"here is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \n",
    "    # Informal / common text contractions\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"gotta\": \"got to\",\n",
    "    \"lemme\": \"let me\",\n",
    "    \"gimme\": \"give me\",\n",
    "    \"kinda\": \"kind of\",\n",
    "    \"ain’t\": \"am not\",\n",
    "    \"y’all\": \"you all\",\n",
    "    \"could’ve\": \"could have\",\n",
    "    \"should’ve\": \"should have\",\n",
    "    \"would’ve\": \"would have\",\n",
    "    \"might’ve\": \"might have\",\n",
    "    \"must’ve\": \"must have\",\n",
    "    \"shan’t\": \"shall not\",\n",
    "    \"let’s\": \"let us\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5463d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text):\n",
    "    for contraction, expanded in contraction_map.items():\n",
    "        text = text.replace(contraction, expanded)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b8a69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset/total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f19f6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Body_question'] = (df['Body_question']\n",
    "    .apply(html.unescape)\n",
    "    .str.replace(r'<[a-zA-Z/][^>]*>', '', regex=True)  # Only remove HTML tags\n",
    "    .str.replace(r'\\n+', ' ', regex=True)              # Only collapse newlines\n",
    "    .str.replace(r'  +', ' ', regex=True)              # Only collapse multiple spaces\n",
    "    .str.replace('\\r','')\n",
    "    .str.replace('’',\"'\")\n",
    "    .str.lower()\n",
    "    .str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92612ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Body_answer'] = (df['Body_answer']\n",
    "    .apply(html.unescape)\n",
    "    .str.replace(r'<[a-zA-Z/][^>]*>', '', regex=True)  # Only remove HTML tags\n",
    "    .str.replace(r'\\n+', ' ', regex=True)              # Only collapse newlines\n",
    "    .str.replace(r'  +', ' ', regex=True)              # Only collapse multiple spaces\n",
    "    .str.replace('\\r','')\n",
    "    .str.replace('’',\"'\")\n",
    "    .str.lower()\n",
    "    .str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "445e0831",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = (df['Title']  # Only remove HTML tags\n",
    "    .str.replace(r'\\n+', ' ', regex=True)              # Only collapse newlines\n",
    "    .str.replace(r'  +', ' ', regex=True)              # Only collapse multiple spaces\n",
    "    .str.replace('\\r','')\n",
    "    .str.lower()\n",
    "    .str.replace('’',\"'\")\n",
    "    .str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23a8906",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) - {\"not\", \"no\", \"never\"}\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_text(text):\n",
    "    # 1. Tokenize first (keeps spacing intact)\n",
    "    text = expand_contractions(text)\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # 2. Lowercase and keep only alphabetic words\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "    # 3. Remove stopwords\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "\n",
    "    # 4. Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "\n",
    "    # 5. Rejoin safely with spaces\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6658df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df['Body_question'] = df['Body_question'].apply(preprocess_text)\n",
    "df['Body_answer'] = df['Body_answer'].apply(preprocess_text)\n",
    "df['Title'] = df['Title'].apply(preprocess_text)\"\"\" #Takes 20 min to run on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "880b5359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Dataset/cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a56e63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebf4efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5f1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
