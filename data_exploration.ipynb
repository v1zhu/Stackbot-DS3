{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58aa1968",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "This notebook will allow us to explore the data found in the Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4177c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import html\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4adf48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'questions = pd.read_csv(\"Dataset/Questions.csv\",encoding=\\'latin-1\\')\\nanswers = pd.read_csv(\"Dataset/Answers.csv\",encoding=\\'latin-1\\')\\ntags = pd.read_csv(\"Dataset/Tags.csv\",encoding=\\'latin-1\\')\\ntag_question = tags.groupby(\\'Id\\').agg(list).merge(questions,how=\\'inner\\',on = \"Id\")\\ndf = tag_question.merge(answers,how = \"inner\",left_on = \"Id\", right_on = \"ParentId\")\\ndf.columns = df.columns.str.replace(\"_x\",\"_question\").str.replace(\"_y\",\"_answer\")\\ndf = df[[\\'Id\\',\\'Tag\\',\\'Score_question\\',\\'Title\\',\\'Body_question\\',\"Score_answer\",\"Body_answer\"]]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"questions = pd.read_csv(\"Dataset/Questions.csv\",encoding='latin-1')\n",
    "answers = pd.read_csv(\"Dataset/Answers.csv\",encoding='latin-1')\n",
    "tags = pd.read_csv(\"Dataset/Tags.csv\",encoding='latin-1')\n",
    "tag_question = tags.groupby('Id').agg(list).merge(questions,how='inner',on = \"Id\")\n",
    "df = tag_question.merge(answers,how = \"inner\",left_on = \"Id\", right_on = \"ParentId\")\n",
    "df.columns = df.columns.str.replace(\"_x\",\"_question\").str.replace(\"_y\",\"_answer\")\n",
    "df = df[['Id','Tag','Score_question','Title','Body_question',\"Score_answer\",\"Body_answer\"]]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51bebb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset/total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254cc6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_map = {\n",
    "    # Negative contractions\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \n",
    "    # Pronoun contractions\n",
    "    \"i'm\": \"i am\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \n",
    "    # Misc contractions\n",
    "    \"let's\": \"let us\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"here's\": \"here is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \n",
    "    # Informal / common text contractions\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"gotta\": \"got to\",\n",
    "    \"lemme\": \"let me\",\n",
    "    \"gimme\": \"give me\",\n",
    "    \"kinda\": \"kind of\",\n",
    "    \"ain’t\": \"am not\",\n",
    "    \"y’all\": \"you all\",\n",
    "    \"could’ve\": \"could have\",\n",
    "    \"should’ve\": \"should have\",\n",
    "    \"would’ve\": \"would have\",\n",
    "    \"might’ve\": \"might have\",\n",
    "    \"must’ve\": \"must have\",\n",
    "    \"shan’t\": \"shall not\",\n",
    "    \"let’s\": \"let us\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5463d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text):\n",
    "    for contraction, expanded in contraction_map.items():\n",
    "        text = text.replace(contraction, expanded)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f19f6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Body_question'] = (df['Body_question']\n",
    "    .apply(html.unescape)\n",
    "    .str.replace(r'<[a-zA-Z/][^>]*>', '', regex=True)  # Only remove HTML tags\n",
    "    .str.replace(r'\\n+', ' ', regex=True)              # Only collapse newlines\n",
    "    .str.replace(r'  +', ' ', regex=True)              # Only collapse multiple spaces\n",
    "    .str.replace('\\r','')\n",
    "    .str.replace('’',\"'\")\n",
    "    .str.lower()\n",
    "    .str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92612ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Body_answer'] = (df['Body_answer']\n",
    "    .apply(html.unescape)\n",
    "    .str.replace(r'<[a-zA-Z/][^>]*>', '', regex=True)  # Only remove HTML tags\n",
    "    .str.replace(r'\\n+', ' ', regex=True)              # Only collapse newlines\n",
    "    .str.replace(r'  +', ' ', regex=True)              # Only collapse multiple spaces\n",
    "    .str.replace('\\r','')\n",
    "    .str.replace('’',\"'\")\n",
    "    .str.lower()\n",
    "    .str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "445e0831",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = (df['Title']  # Only remove HTML tags\n",
    "    .str.replace(r'\\n+', ' ', regex=True)              # Only collapse newlines\n",
    "    .str.replace(r'  +', ' ', regex=True)              # Only collapse multiple spaces\n",
    "    .str.replace('\\r','')\n",
    "    .str.lower()\n",
    "    .str.replace('’',\"'\")\n",
    "    .str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23a8906",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) - {\"not\", \"no\", \"never\"}\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_text(text):\n",
    "    # Expand contractions\n",
    "    text = expand_contractions(text)\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Lowercase and keep only alphabetic words\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "\n",
    "    # Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6658df45",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody_question\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBody_question\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody_answer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody_answer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(preprocess_text)\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(preprocess_text) \u001b[38;5;66;03m#Takes 20 min to run on full dataset\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 20\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     17\u001b[0m tokens \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mpos_tag(tokens)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Lemmatize\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [\u001b[43mlemmatizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mget_wordnet_pos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tokens]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tokens)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/nltk/stem/wordnet.py:85\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, word: \u001b[38;5;28mstr\u001b[39m, pos: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     61\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Lemmatize `word` by picking the shortest of the possible lemmas,\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    using the wordnet corpus reader's built-in _morphy function.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    Returns the input word unchanged if it cannot be found in WordNet.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    :return: The shortest lemma of `word`, for the given `pos`.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morphy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(lemmas, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m lemmas \u001b[38;5;28;01melse\u001b[39;00m word\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dsc80/lib/python3.12/site-packages/nltk/stem/wordnet.py:39\u001b[0m, in \u001b[0;36mWordNetLemmatizer._morphy\u001b[0;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_morphy\u001b[39m(\u001b[38;5;28mself\u001b[39m, form, pos, check_exceptions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    _morphy() is WordNet's _morphy lemmatizer.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    It returns a list of all lemmas found in WordNet.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    ['us', 'u']\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wordnet \u001b[38;5;28;01mas\u001b[39;00m wn\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wn\u001b[38;5;241m.\u001b[39m_morphy(form, pos, check_exceptions)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1390\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['Body_question'] = df['Body_question'].apply(preprocess_text)\n",
    "df['Title'] = df['Title'].apply(preprocess_text) #Takes 20 min to run on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae133d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question'] = df['Title'] + \" \" + df['Body_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "511b11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Id','Tag','Score_question','question','Score_answer','Body_answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "880b5359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Dataset/cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12defab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Score_question</th>\n",
       "      <th>question</th>\n",
       "      <th>Score_answer</th>\n",
       "      <th>Body_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>469</td>\n",
       "      <td>['python', 'osx', 'fonts', 'photoshop']</td>\n",
       "      <td>21</td>\n",
       "      <td>find full path font display name mac using pho...</td>\n",
       "      <td>4</td>\n",
       "      <td>open up a terminal (applications-&gt;utilities-&gt;t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>469</td>\n",
       "      <td>['python', 'osx', 'fonts', 'photoshop']</td>\n",
       "      <td>21</td>\n",
       "      <td>find full path font display name mac using pho...</td>\n",
       "      <td>2</td>\n",
       "      <td>i haven't been able to find anything that does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>469</td>\n",
       "      <td>['python', 'osx', 'fonts', 'photoshop']</td>\n",
       "      <td>21</td>\n",
       "      <td>find full path font display name mac using pho...</td>\n",
       "      <td>12</td>\n",
       "      <td>unfortunately the only api that isn't deprecat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>469</td>\n",
       "      <td>['python', 'osx', 'fonts', 'photoshop']</td>\n",
       "      <td>21</td>\n",
       "      <td>find full path font display name mac using pho...</td>\n",
       "      <td>1</td>\n",
       "      <td>there must be a method in cocoa to get a list ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>502</td>\n",
       "      <td>['python', 'windows', 'image', 'pdf']</td>\n",
       "      <td>27</td>\n",
       "      <td>get preview jpeg pdf window python application...</td>\n",
       "      <td>9</td>\n",
       "      <td>you can use imagemagick's convert utility for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987117</th>\n",
       "      <td>40142948</td>\n",
       "      <td>['python', 'tuples']</td>\n",
       "      <td>-2</td>\n",
       "      <td>make function return tuple divided multiple li...</td>\n",
       "      <td>0</td>\n",
       "      <td>hereâs the quick and dirty way: def formatte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987118</th>\n",
       "      <td>40143133</td>\n",
       "      <td>['python', 'beautifulsoup']</td>\n",
       "      <td>1</td>\n",
       "      <td>error handling beautifulsoup scraped url not r...</td>\n",
       "      <td>1</td>\n",
       "      <td>you may check the value of name_box variable -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987119</th>\n",
       "      <td>40143166</td>\n",
       "      <td>['python', 'python-3.x']</td>\n",
       "      <td>1</td>\n",
       "      <td>finding cubed root using delta epsilon python ...</td>\n",
       "      <td>2</td>\n",
       "      <td>first thing, you should use if/elif instead of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987120</th>\n",
       "      <td>40143190</td>\n",
       "      <td>['python', 'bash', 'multiline']</td>\n",
       "      <td>1</td>\n",
       "      <td>execute multiline python code bash script need...</td>\n",
       "      <td>5</td>\n",
       "      <td>use a here-doc: result=$(python &lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987121</th>\n",
       "      <td>40143190</td>\n",
       "      <td>['python', 'bash', 'multiline']</td>\n",
       "      <td>1</td>\n",
       "      <td>execute multiline python code bash script need...</td>\n",
       "      <td>0</td>\n",
       "      <td>tanks to this so answer i found the answer mys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>987122 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id                                      Tag  Score_question  \\\n",
       "0            469  ['python', 'osx', 'fonts', 'photoshop']              21   \n",
       "1            469  ['python', 'osx', 'fonts', 'photoshop']              21   \n",
       "2            469  ['python', 'osx', 'fonts', 'photoshop']              21   \n",
       "3            469  ['python', 'osx', 'fonts', 'photoshop']              21   \n",
       "4            502    ['python', 'windows', 'image', 'pdf']              27   \n",
       "...          ...                                      ...             ...   \n",
       "987117  40142948                     ['python', 'tuples']              -2   \n",
       "987118  40143133              ['python', 'beautifulsoup']               1   \n",
       "987119  40143166                 ['python', 'python-3.x']               1   \n",
       "987120  40143190          ['python', 'bash', 'multiline']               1   \n",
       "987121  40143190          ['python', 'bash', 'multiline']               1   \n",
       "\n",
       "                                                 question  Score_answer  \\\n",
       "0       find full path font display name mac using pho...             4   \n",
       "1       find full path font display name mac using pho...             2   \n",
       "2       find full path font display name mac using pho...            12   \n",
       "3       find full path font display name mac using pho...             1   \n",
       "4       get preview jpeg pdf window python application...             9   \n",
       "...                                                   ...           ...   \n",
       "987117  make function return tuple divided multiple li...             0   \n",
       "987118  error handling beautifulsoup scraped url not r...             1   \n",
       "987119  finding cubed root using delta epsilon python ...             2   \n",
       "987120  execute multiline python code bash script need...             5   \n",
       "987121  execute multiline python code bash script need...             0   \n",
       "\n",
       "                                              Body_answer  \n",
       "0       open up a terminal (applications->utilities->t...  \n",
       "1       i haven't been able to find anything that does...  \n",
       "2       unfortunately the only api that isn't deprecat...  \n",
       "3       there must be a method in cocoa to get a list ...  \n",
       "4       you can use imagemagick's convert utility for ...  \n",
       "...                                                   ...  \n",
       "987117  hereâs the quick and dirty way: def formatte...  \n",
       "987118  you may check the value of name_box variable -...  \n",
       "987119  first thing, you should use if/elif instead of...  \n",
       "987120                  use a here-doc: result=$(python <  \n",
       "987121  tanks to this so answer i found the answer mys...  \n",
       "\n",
       "[987122 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('Dataset/cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab786cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
